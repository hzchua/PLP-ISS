# -*- coding: utf-8 -*-
"""1_TextSummarization - Pipelines_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pkyyDfCypyUnt7mhDYnovICyf5uqnRDK
"""

!pip install nltk
!pip install ijson
!pip install transformers 
!pip install SentencePiece

import os
import json
import string
import nltk
from nltk import word_tokenize, FreqDist
from nltk.corpus import stopwords
import gzip
import json
import ast
import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler
#from transformers import T5Tokenizer, T5ForConditionalGeneration
from transformers import pipeline
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

### Initialization Variable### 
input_path = '/content/drive/MyDrive/PLP Practice Module/df_CA.json' 
output_path = '/content/drive/MyDrive/PLP Practice Module/df_CA_Summarization.csv'
output_sep = '^'

def load_data(): 
  with open(input_path) as json_file:     
    data = json_file.readlines()
    data = list(map(json.loads, data)) 
  return pd.DataFrame(data)

def textSummarization_Pipelines(): 
  # use bart in pytorch
  summarizer = pipeline("summarization")
  # load data
  df = load_data()
  # remove special char, to be used as csv separator later
  df['reviewText'] = df['reviewText'].str.replace('^','') 
  df["sumText"] = summarizer(df['reviewText'].tolist(), max_length=20, min_length=5, do_sample=False)
  df.to_csv(output_path, sep=output_sep)

# call textSummarization_Pipelines()
textSummarization_Pipelines()